---
title: AI Writes the Code Now. Learning to Program Just Got Harder.
date: 2026-01-23
draft: false
slug: /blog/learning-programming-just-got-harder
template: post
---

For a long time, writing code was the hard part.

You had to remember syntax, internalize patterns, fight the compiler, and slowly build an intuition for what worked and what didn’t. The feedback loop was slow, sometimes brutal, but it was formative. You earned every small win.

That’s no longer true.

Today, code is cheap. Abundant. Almost disposable.
AI can write entire features, refactor existing systems, generate tests, and explain unfamiliar codebases in seconds. In many cases, it does this faster — and often better — than a junior developer.

This isn’t a prediction. It’s already happening.

And while most of the conversation has focused on what this means for productivity, hiring, or the future of engineering jobs, there’s a quieter and more uncomfortable question underneath it all:

How are junior developers supposed to learn now?

## The bottleneck moved

AI didn’t just automate a task. It moved the bottleneck.

In the past, the limiting factor was writing code. Today, the limiting factor is understanding what the code does, why it exists, and how it behaves when things go wrong.

That distinction matters — especially for juniors.

If outputting code is the metric, juniors can’t compete with AI. And honestly, they shouldn’t try. That’s a losing game from day one.

But most learning paths, tutorials, and even job expectations are still optimized for the old world — the one where typing code was the primary skill to develop.

The result is a dangerous mismatch:
tools that make it easy to skip the very experiences that used to build intuition.

## How I learned (and why it mattered)

Years ago, I wrote an article called ["An approach to learning programming languages."](../learning-programming-languages)
The core idea was simple: learning a language isn’t about syntax. It’s about learning how problems are expressed and solved within a set of constraints.

What I didn’t emphasize enough back then is how much of that learning came from struggle.

Not heroic struggle. Not romantic suffering. Just… friction.
• Code that compiled but behaved incorrectly
• Bugs that took hours to isolate
• Refactors that broke things in subtle ways
• Patterns that only made sense after misusing them

I learned slowly. Often painfully.

I didn’t just learn what to write — I learned what didn’t work, and more importantly, why. That "why" became instinct over time. Not because I memorized it, but because I had felt the cost of getting it wrong.

That process wasn’t efficient. But it worked.

## What AI changes for juniors

AI makes it possible — even tempting — to bypass that entire phase.

You can now:
• Generate working solutions without fully understanding them
• Fix errors without knowing their root cause
• Ship features without forming a mental model of the system

And here’s the dangerous part: this doesn’t fail immediately.

In fact, it often looks like success.
• The code works
• The task is done
• The PR gets approved

But the cost isn’t gone. It’s deferred.

It shows up later:
• When the system behaves unexpectedly
• When performance degrades
• When trade-offs matter
• When debugging requires intuition, not syntax

At that point, the gap is painful — not because AI was used, but because it replaced thinking instead of amplifying it.

## Skipping the struggle has consequences

There are a few things juniors risk missing if AI becomes a permanent crutch early on:

1. Mental models

   Without wrestling with problems yourself, it’s hard to build a clear picture of how things actually work. You can recognize patterns without understanding them — which breaks down fast at scale.

2. Debugging instincts

   Debugging isn’t a skill you read about. It’s pattern recognition built from past failures. If you’ve never been lost in a system, you won’t know how to find your way out.

3. Taste

   Good code isn’t just correct — it’s appropriate. Taste comes from seeing many bad solutions, including your own. AI can give you "working," but it won’t give you taste unless you already have a baseline.

None of this means AI is harmful by default.

It means using it too early, in the wrong way, changes what you learn.

## But let’s be honest: the struggle is real

It would be easy to stop here and say: "So just don’t use AI."

That advice is useless.

The reality juniors are facing today is very different from the one I learned in:
• Faster expectations
• More competition
• Less tolerance for ramp-up time
• Constant comparison to AI-level output

AI doesn’t feel like cheating. It feels like relief.

It helps with impostor syndrome. It reduces anxiety. It keeps you moving forward. And when you’re trying to break into an industry that already feels hostile, "struggling more" sounds like terrible advice.

That context matters.

So the answer isn’t abstinence. It’s intentional use.

## A better way to use AI while learning

Instead of asking "Should juniors use AI?", a better question is:

What should AI replace — and what should it never replace?

Some principles that actually work:

Use AI after you form a hypothesis

Try to reason about the solution first. Even a bad attempt counts. Then use AI to compare approaches, spot gaps, or validate assumptions.

## Ask "why", not just "what"

Generated code is cheap. Explanations are valuable. Use AI to interrogate decisions, not just produce results.

Rebuild small things without AI — on purpose

Not everything. Just enough to stay sharp. Toy problems, utilities, small services. This is where intuition still forms.

Treat AI like a senior reviewer, not a generator

A good senior doesn’t write everything for you — they guide, challenge, and correct. That’s the mental model that scales.

The goal isn’t to slow yourself down artificially.
It’s to make sure understanding keeps pace with output.

## The new apprenticeship

AI didn’t eliminate the need to learn fundamentals. It made it easier to avoid them.

That’s the trap.

The juniors who will struggle most aren’t the ones using AI — they’re the ones who never learned how to think without it. The gap won’t show up on day one. It will show up when systems get messy, ambiguous, and unforgiving.

The path I took still works.
It’s just easier to skip now.

And skipping it feels fine — until it doesn’t.
